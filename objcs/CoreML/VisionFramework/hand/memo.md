# ğŸ“ 2022/11/03

## delegate å‘¼ã¹ãŸï¼Ÿ

`captureOutput_didOutputSampleBuffer_fromConnection_` ã®ã¿å‘¼ã³å‡ºã—ã¦ã„ãŸãŒã€`captureOutput_didDropSampleBuffer_fromConnection_` ã‚‚å‘¼ã³å‡ºã—ã¦ã¿ã¦ã‚‹


[captureOutput:didDropSampleBuffer:fromConnection: | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturevideodataoutputsamplebufferdelegate/1388468-captureoutput?language=objc)




> ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

> é…å»¶ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ãŒãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚Œã‚‹ãŸã³ã«ã€Delegate ã¯ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã« 1 å›å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚å‡ºåŠ›ã® sampleBufferCallbackQueue ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã§æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ ã‚­ãƒ¥ãƒ¼ã§å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚

> sampleBuffer ã«ã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãŒãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸç†ç”±ã®è©³ç´°ã‚’ç¤ºã™ kCMSampleBufferAttachmentKey_DroppedFrameReason æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¾ã™ã€‚ãƒ•ãƒ¬ãƒ¼ãƒ ãŒãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸç†ç”±ã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãŒé…å»¶ã—ãŸãŸã‚ (kCMSampleBufferDroppedFrameReason_FrameWasLate) ã§ã€é€šå¸¸ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ããŸãŸã‚ã«èµ·ã“ã‚Šã¾ã—ãŸã€‚ã¾ãŸã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æä¾›ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒãƒƒãƒ•ã‚¡ä¸è¶³ã®ãŸã‚ã€ãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ï¼ˆkCMSampleBufferDroppedFrameReason_OutOfBuffersï¼‰ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒ•ã‚¡ã‚’æä¾›ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä¸é€£ç¶šã‚’çµŒé¨“ã—ï¼ˆkCMSampleBufferDroppedFrameReason_Discontinuityï¼‰ã€æœªçŸ¥ã®æ•°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå¤±ã‚ã‚ŒãŸå ´åˆã«ã‚‚ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãŒãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®çŠ¶æ…‹ã¯ã€é€šå¸¸ã€ã‚·ã‚¹ãƒ†ãƒ ãŒãƒ“ã‚¸ãƒ¼çŠ¶æ…‹ã§ã‚ã‚‹ã“ã¨ãŒåŸå› ã§ã™ã€‚

> ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã®å‡ºåŠ›ã‚’æ‹…å½“ã™ã‚‹åŒã˜ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã‚­ãƒ¥ãƒ¼ã§å‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã‚ã€ãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã®è¿½åŠ ãªã©ã€ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å•é¡Œã‚’é˜²ããŸã‚ã«åŠ¹ç‡çš„ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚




[captureOutput:didOutputSampleBuffer:fromConnection: | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturevideodataoutputsamplebufferdelegate/1385775-captureoutput?language=objc)


> ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

> videoSettings ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã§æŒ‡å®šã•ã‚ŒãŸé€šã‚Šã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã€æ–°ã—ã„ãƒ“ãƒ‡ã‚ª ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦å‡ºåŠ›ã™ã‚‹ã¨ã€ãƒ‡ã‚£ãƒ¬ã‚²ãƒ¼ãƒˆã¯ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ã¾ã™ã€‚ãƒ‡ãƒªã‚²ãƒ¼ãƒˆã¯ã€æä¾›ã•ã‚ŒãŸãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä»–ã® API ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã—ã€ã•ã‚‰ã«å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

> ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å‡ºåŠ›ã® sampleBufferCallbackQueue ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã«ã‚ˆã£ã¦æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ ã‚­ãƒ¥ãƒ¼ã§å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚å®šæœŸçš„ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã‚ã€ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å«ã‚€ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å•é¡Œã‚’é˜²ããŸã‚ã«åŠ¹ç‡çš„ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚
> ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã®ç¯„å›²å¤–ã§CMSampleBufferã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å‚ç…§ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€CFRetainã—ã€ãã‚ŒãŒçµ‚äº†ã—ãŸã‚‰CFReleaseã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

> æœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã™ã‚‹ãŸã‚ã«ã€ã„ãã¤ã‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒ•ã‚¡ã¯ã€ãƒ‡ãƒã‚¤ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã¨ä»–ã®ã‚­ãƒ£ãƒ—ãƒãƒ£å…¥åŠ›ã«ã‚ˆã£ã¦å†ä½¿ç”¨ã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãƒ¡ãƒ¢ãƒªã®ãƒ—ãƒ¼ãƒ«ã‚’ç›´æ¥å‚ç…§ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€éåœ§ç¸®ã®ãƒ‡ãƒã‚¤ã‚¹ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚­ãƒ£ãƒ—ãƒãƒ£ã§ã€ãƒ¡ãƒ¢ãƒªãƒ–ãƒ­ãƒƒã‚¯ã®ã‚³ãƒ”ãƒ¼ã‚’ã§ãã‚‹ã ã‘å°‘ãªãã™ã‚‹å ´åˆã«ã‚ˆãã‚ã‚‹ã“ã¨ã§ã™ã€‚è¤‡æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒ•ã‚¡ãŒãã®ã‚ˆã†ãªãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚’é•·ãå‚ç…§ã—ã¦ã„ã‚‹ã¨ã€å…¥åŠ›ã¯æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼ã™ã‚‹ã“ã¨ãŒã§ããªããªã‚Šã€ãã‚Œã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚

> ã‚‚ã—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæä¾›ã•ã‚ŒãŸ CMSampleBufferRef ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é•·ãä¿æŒã™ã‚‹ã“ã¨ã§ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚’å¼•ãèµ·ã“ã—ã¦ã„ã‚‹ãŒã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã«é•·æœŸé–“ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã«ã‚³ãƒ”ãƒ¼ã—ã¦ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒ•ã‚¡ã‚’è§£æ”¾ã—ï¼ˆä»¥å‰ã«ä¿æŒã—ã¦ã„ãŸå ´åˆï¼‰ã€ãã‚ŒãŒå‚ç…§ã™ã‚‹ãƒ¡ãƒ¢ãƒªã‚’å†ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚


# ğŸ“ 2022/11/02

## `delegate` ã‚’ class å†…ã«å…¥ã‚Œã‚‹ã¨ã€60 ãã‚‰ã„ã§å‘¼ã³å‡ºã•ãªããªã‚‹

[face_detector.py strange behavior | omz:forum](https://forum.omz-software.com/topic/6434/face_detector-py-strange-behavior)

### pavlinb

> ã“ã“([iPhone ã®ã‚«ãƒ¡ãƒ©ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¡”æ¤œå‡ºï¼ˆPythonista ç·¨ï¼‰ - Qiita](https://qiita.com/inasawa/items/3e730c338bcefd522fb8))ã‹ã‚‰ face_detector.py ã‚’å‹‰å¼·ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚
> ã“ã“ã§ã¯ã€ãƒ“ãƒ‡ã‚ªã‚«ãƒ¡ãƒ©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«æ¤œå‡ºå™¨ã‚’é©ç”¨ã—ã¦ã„ã¾ã™ã€‚

> å•é¡Œã¯ 80-90 ãƒ•ãƒ¬ãƒ¼ãƒ ã§ç™ºç”Ÿã—ã¾ã™ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯å˜ã«åœæ­¢ã—ã¾ã™ãŒã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¾ã›ã‚“ã€‚

> ãªãœæ­¢ã¾ã‚‹ã®ã‹ã€ã©ã†ã™ã‚Œã°é˜²ã’ã‚‹ã®ã‹ãŒã‚ã‹ã‚Šã¾ã›ã‚“ã€‚

> ä½•ã‹ã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ


```.py
# coding: utf-8

from objc_util import *
from ctypes import c_void_p
import ui
import time

# å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã—ã‚ˆã†ã¨ã™ã‚‹ã¨å‹•ã‹ãªããªã‚‹ã®ã§ã“ã®ç¨‹åº¦ã§
FRAME_INTERVAL = 6  # 30fps / 6 = 5fps

frame_counter = 0
last_fps_time = time.time()
fps_counter = 0

AVCaptureSession = ObjCClass('AVCaptureSession')
AVCaptureDevice = ObjCClass('AVCaptureDevice')
AVCaptureDeviceInput = ObjCClass('AVCaptureDeviceInput')
AVCaptureVideoDataOutput = ObjCClass('AVCaptureVideoDataOutput')
AVCaptureVideoPreviewLayer = ObjCClass('AVCaptureVideoPreviewLayer')

CIImage    = ObjCClass('CIImage')
CIDetector = ObjCClass('CIDetector')

dispatch_get_current_queue = c.dispatch_get_current_queue
dispatch_get_current_queue.restype = c_void_p

CMSampleBufferGetImageBuffer = c.CMSampleBufferGetImageBuffer
CMSampleBufferGetImageBuffer.argtypes = [c_void_p]
CMSampleBufferGetImageBuffer.restype = c_void_p

CVPixelBufferLockBaseAddress = c.CVPixelBufferLockBaseAddress
CVPixelBufferLockBaseAddress.argtypes = [c_void_p, c_int]
CVPixelBufferLockBaseAddress.restype = None

CVPixelBufferGetWidth = c.CVPixelBufferGetWidth
CVPixelBufferGetWidth.argtypes = [c_void_p]
CVPixelBufferGetWidth.restype = c_int

CVPixelBufferGetHeight = c.CVPixelBufferGetHeight
CVPixelBufferGetHeight.argtypes = [c_void_p]
CVPixelBufferGetHeight.restype = c_int

CVPixelBufferUnlockBaseAddress = c.CVPixelBufferUnlockBaseAddress
CVPixelBufferUnlockBaseAddress.argtypes = [c_void_p, c_int]
CVPixelBufferUnlockBaseAddress.restype = None


def captureOutput_didOutputSampleBuffer_fromConnection_(_self, _cmd, _output, _sample_buffer, _conn):
    global frame_counter, fps_counter, last_fps_time
    global image_width, image_height, faces

    # æ€§èƒ½ç¢ºèªã®ãŸã‚ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã®å®Ÿ FPS è¡¨ç¤º
    fps_counter += 1
    now = time.time()
    if int(now) > int(last_fps_time):
        label_fps.text = '{:5.2f} fps'.format((fps_counter) / (now - last_fps_time))
        last_fps_time = now
        fps_counter = 0

    # ç”»åƒå‡¦ç†ã¯ FRAME_INTERVAL é–“éš”ã§å‡¦ç†
    if frame_counter == 0:
        # ãƒ“ãƒ‡ã‚ªç”»åƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        imagebuffer =  CMSampleBufferGetImageBuffer(_sample_buffer)
        # ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ­ãƒƒã‚¯
        CVPixelBufferLockBaseAddress(imagebuffer, 0)

        image_width  = CVPixelBufferGetWidth(imagebuffer)
        image_height = CVPixelBufferGetHeight(imagebuffer)
        ciimage = CIImage.imageWithCVPixelBuffer_(ObjCInstance(imagebuffer))

        # CIDetector ã«ã‚ˆã‚Šé¡”æ¤œå‡º
        options = {'CIDetectorAccuracy': 'CIDetectorAccuracyHigh'}
        detector = CIDetector.detectorOfType_context_options_('CIDetectorTypeFace', None, options)
        faces = detector.featuresInImage_(ciimage)

        # ãƒãƒƒãƒ•ã‚¡ã®ãƒ­ãƒƒã‚¯ã‚’è§£æ”¾
        CVPixelBufferUnlockBaseAddress(imagebuffer, 0)

        # æ¤œå‡ºã—ãŸé¡”ã®æƒ…å ±ã‚’ä½¿ã£ã¦è¡¨ç¤ºã‚’æ›´æ–°
        path_view.set_needs_display()

    frame_counter = (frame_counter + 1) % FRAME_INTERVAL

class PathView(ui.View):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def draw(self):
        # æ¤œå‡ºã—ãŸé¡”ã®è¼ªéƒ­ã«åˆã‚ã›ã¦ã€è¡¨ç¤ºã‚’åŠ å·¥
        if faces is not None and faces.count() != 0:
            # é¡”ã®éƒ¨åˆ†ã‚’ç™½ãè¦†ã†
            ui.set_color((1, 1, 1, 0.9))
            for face in faces:
                face_bounds = face.bounds()
                # ã‚«ãƒ¡ãƒ©ã®ç”»åƒã¯ Xè»¸=1920 Yè»¸=1080
                # View ã¯ Xè»¸=375 Yè»¸=667
                # ç”»åƒã®Xè»¸Yè»¸ã‚’Viewã®Yè»¸Xè»¸ã«å¯¾å¿œã•ã›ã€ã‚µã‚¤ã‚ºã‚’èª¿æ•´
                x = face_bounds.origin.y    * self.height / image_width
                y = face_bounds.origin.x    * self.width  / image_height
                w = face_bounds.size.height * self.height / image_width
                h = face_bounds.size.width  * self.width  / image_height
                path = ui.Path.oval(x, y, w * 1.3, h)
                path.fill()

@on_main_thread
def main():
    global path_view, label_fps, faces

    # ç”»é¢ã®å›è»¢ã«ã¯å¯¾å¿œã—ã¦ãŠã‚‰ãš
    # iPhoneã®ç”»é¢ç¸¦å‘ãã§ãƒ­ãƒƒã‚¯ã—ãŸçŠ¶æ…‹ã§ã€æ¨ªé•·ç”»é¢ã§ä½¿ã†æƒ³å®š
    # View ã®ã‚µã‚¤ã‚ºã¯æ‰‹æŒã¡ã® iPhone6 ã«åˆã‚ã›ãŸã‚‚ã®
    faces = None
    main_view = ui.View(frame=(0, 0, 375, 667))
    path_view = PathView(frame=main_view.frame)
    main_view.name = 'Face Detector'

    sampleBufferDelegate = create_objc_class(
                                'sampleBufferDelegate',
                                methods=[captureOutput_didOutputSampleBuffer_fromConnection_],
                                protocols=['AVCaptureVideoDataOutputSampleBufferDelegate'])
    delegate = sampleBufferDelegate.new()

    session = AVCaptureSession.alloc().init()
    device = AVCaptureDevice.defaultDeviceWithMediaType_('vide')
    _input = AVCaptureDeviceInput.deviceInputWithDevice_error_(device, None)
    if _input:
        session.addInput_(_input)
    else:
        print('Failed to create input')
        return

    output = AVCaptureVideoDataOutput.alloc().init()
    queue = ObjCInstance(dispatch_get_current_queue())
    output.setSampleBufferDelegate_queue_(delegate, queue)
    output.alwaysDiscardsLateVideoFrames = True

    session.addOutput_(output)
    session.sessionPreset = 'AVCaptureSessionPresetHigh' # 1920 x 1080

    prev_layer = AVCaptureVideoPreviewLayer.layerWithSession_(session)
    prev_layer.frame = ObjCInstance(main_view).bounds()
    prev_layer.setVideoGravity_('AVLayerVideoGravityResizeAspectFill')

    ObjCInstance(main_view).layer().addSublayer_(prev_layer)

    # æ€§èƒ½ç¢ºèªã®ãŸã‚ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã®å®Ÿ FPS è¡¨ç¤º
    label_fps = ui.Label(frame=(0, 0, main_view.width, 30), flex='W', name='fps')
    label_fps.background_color = (0, 0, 0, 0.5)
    label_fps.text_color = 'white'
    label_fps.text = ''
    label_fps.alignment = ui.ALIGN_CENTER

    main_view.add_subview(label_fps)
    main_view.add_subview(path_view)

    session.startRunning()

    main_view.present('sheet')
    main_view.wait_modal()

    session.stopRunning()
    delegate.release()
    session.release()
    output.release()

if __name__ == '__main__':
    main()
```

### JonB

> ã‚‚ã—ã€frame_xounter ãŒå¤§ãããªã£ãŸã‚‰ã€frame_counter ã¨ last frame time ã‚’å®šæœŸçš„ã« 0 ã«ãƒªã‚»ãƒƒãƒˆã™ã‚‹æ–¹æ³•ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ã‚‚ã‚ˆã„ã§ã—ã‚‡ã†ã€‚

> ã¾ãŸã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“ã€frame_counterã€ãŠã‚ˆã³ç¾åœ¨æ™‚é–“ã§æ›´æ–°ã•ã‚Œã‚‹ãƒ©ãƒ™ãƒ«ã‚’æŒã¤ - ã“ã‚Œã‚‰ã¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ã®ãƒ­ã‚¸ãƒƒã‚¯ã§ä½¿ç”¨ã•ã‚Œã‚‹ã‹ã‚‰ã§ã™ã€‚


### pavlinb

> è‡ªå‹•ãƒ­ãƒƒã‚¯å¾Œã€æºå¸¯é›»è©±ãŒèµ·å‹•ã™ã‚‹ã¨ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒã•ã‚‰ã« 80 ï½ 90 ãƒ‘ã‚¹ã—ã¦ã€å†ã³ãƒãƒ³ã‚°ã™ã‚‹ã€‚

### JonB

> ã‚ã‹ã‚Šã¾ã—ãŸã€ã„ãã¤ã‹å•é¡ŒãŒã‚ã‚‹ã‚ˆã†ã§ã™ã€‚

> ã¾ãšã€didDropSampleBuffer ãƒ‡ãƒªã‚²ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…ã—ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãŒé…ã‚ŒãŸç†ç”±ã‚’è¡¨ç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

> 2 ã¤ç›®ã¯ã€minFrameDuration ã‚’è¨­å®šã—ã¦ã€ãƒ‡ãƒªã‚²ãƒ¼ãƒˆãŒå¿…è¦ä»¥ä¸Šã«å‘¼ã³å‡ºã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã“ã‚Œã¯ output.minFrameDuration ã«ã‚ã£ãŸã¨æ€ã„ã¾ã™ã€‚æ–°ã—ã„ iOS ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€æ¥ç¶šã§è¨­å®šã™ã‚‹ã¨æ€ã„ã¾ã™ã€ output.connections[0].videoMinFrameDuration

> ç¬¬ä¸‰ã«ã€ã©ã®ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã‚­ãƒ¥ãƒ¼ã§å‘¼ã³å‡ºã•ã‚Œã‚‹ã‹ã¨ã„ã†å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã‚ã‚‹ã„ã¯ã€ãƒ‡ãƒªã‚²ãƒ¼ãƒˆã¯å¸¸ã«ã§ãã‚‹ã ã‘é€Ÿãæˆ»ã‚‹å¿…è¦ãŒã‚ã‚Šã€åˆ¥ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã§é‡ã„ä»•äº‹ã‚’å‘¼ã³å‡ºã—ã€ãã†ã§ãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ã‚’è½ã¨ã—ã¾ã™ã€‚

> å¾Œã§æ”¹è‰¯ã—ãŸ gist ã‚’æŠ•ç¨¿ã—ã¾ã™ã€‚

### pavlinb

> ã‚‚ã†ä¸€ã¤ã®è‰¯ã„ä¾‹ã‚’ã“ã“([Image capture system with AVCaptureStillImageOutput.](https://gist.github.com/Cethric/83a4b2ccf25798d5e074))ã§ãƒ†ã‚¹ãƒˆã—ã¦ã¿ã¾ã—ãŸã€‚

> ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯

> `self.captureOutput.setMinFrameDuration_(CMTimeMake(1, 2), argtypes=[CMTime], restype=None)` ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

> `CMTimeMake(.,.)`ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

> æ®‹å¿µãªãŒã‚‰ã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ã—ã¦ã—ã¾ã„ã¾ã™ã€‚

### JonB

> Cethric ã®ã‚‚ã®ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒã£ã¦ã„ã¾ã™ã€‚å¾Œæ—¥ã€ãã‚Œã„ã«ã—ã¦æŠ•ç¨¿ã—ã¾ã™ã€‚ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè£…ã—ãŸã®ã§ã€ä½•ãŒå•é¡Œã‹ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚

> ç§ãŒè¦‹ã¤ã‘ãŸ 1 ã¤ã®å•é¡Œã¯ã€minFrameDuration ã‚’è¨­å®šã™ã‚‹æ§˜ã€…ãªæ–¹æ³•ãŒæ©Ÿèƒ½ã—ãªã„ã“ã¨ã§ã™ã€‚ã¤ã¾ã‚Šã€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒé«˜ã„ç¢ºç‡ã§å‘¼ã³å‡ºã•ã‚Œã‚‹ã®ã§ã™ã€‚

### pavlinb

> `setMinFrameDuration` ã¯ã€`camera.captureOutput` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆ`AVCaptureVideoDataOutput`ï¼‰ã«ã‚ã‚‹ã‚ˆã†ã§ã™ã€‚

ã—ã‹ã—ã€`camera.captureDevice` (`AVCaptureDevice`)ã«ã‚‚`setActiveVideoMinFrameDuration` ãŒå­˜åœ¨ã—ã¾ã™ã€‚


> ã©ã¡ã‚‰ã‚‚å‹•ä½œã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚

### JonB

> ã“ã‚Œã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚ [detector.py](https://gist.github.com/jsbain/424d4fe1a3c0b1ae3fd705d72f665c1e)

> FRAME_PROC_INTERVAL ã‚’ã€FrameLate ãŒå¸¸ã«è¡¨ç¤ºã•ã‚Œãªããªã‚‹ã¾ã§å¢—ã‚„ã™ã‹ã€ã¾ãŸã¯ 1 ã«è¨­å®šã—ã¦ã§ãã‚‹ã ã‘é€Ÿãã—ã¾ã™ã€‚

> å®Ÿéš›ã®æœ€å°ãƒ•ãƒ¬ãƒ¼ãƒ é–“éš”ã‚’è¨­å®šã™ã‚‹ãŸã‚ã«ã¯ã€å¤šãã®è¼ªã‚’ããã‚ŠæŠœã‘ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚DESIRED_FPS ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€30fps æœªæº€ã«ã§ãã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

> ã“ã‚Œã¯ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ã—ã¾ã™ã‹ï¼Ÿ ã‚‚ã—ãã†ãªã‚‰ã€æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæˆ»ã£ã¦ããŸã¨ãã«ã©ã‚“ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‡ºã¾ã™ã‹ï¼Ÿ

# ğŸ“ 2022/10/31

[iOS 14 Vision Body Pose Detection: Count Squat Reps in a SwiftUI Workout App | by Philipp Gehrke | Better Programming](https://betterprogramming.pub/ios-14-vision-body-pose-detection-count-squat-reps-in-a-workout-c88991f7cad4)

[Vision ã§èº«ä½“ã‚„æ‰‹ã®ãƒãƒ¼ã‚ºã‚’æ¤œå‡ºã™ã‚‹ â€“ WWDC2020â”‚](https://plum-plus.jp/2020/11/06/vision%e3%81%a7%e8%ba%ab%e4%bd%93%e3%82%84%e6%89%8b%e3%81%ae%e3%83%9d%e3%83%bc%e3%82%ba%e3%82%92%e6%a4%9c%e5%87%ba%e3%81%99%e3%82%8b-wwdc2020/)

### `VNSequenceRequestHandler`

> æ¦‚è¦

> ã“ã®ãƒãƒ³ãƒ‰ãƒ©ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹ã¨ã€ä¸€é€£ã®ç”»åƒã«å¯¾ã—ã¦ Vision ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚VNImageRequestHandler ã¨ã¯ç•°ãªã‚Šã€ä½œæˆæ™‚ã«ç”»åƒã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã¯ãªã„ã€‚ãã®ä»£ã‚ã‚Šã€perform ãƒ¡ã‚½ãƒƒãƒ‰ã® 1 ã¤ã‚’å‘¼ã³ç¶šã‘ã‚‹ã¨ãã«ã€å„ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ 1 ã¤ãšã¤ä¾›çµ¦ã™ã‚‹ã€‚

```.log
availableJointNames: (
    VNHLKRPIP,
    VNHLKTMP,
    VNHLKMTIP,
    VNHLKRMCP,
    VNHLKRDIP,
    VNHLKITIP,
    VNHLKMPIP,
    VNHLKTTIP,
    VNHLKTIP,
    VNHLKIPIP,
    VNHLKPTIP,
    VNHLKWRI,
    VNHLKPPIP,
    VNHLKMMCP,
    VNHLKMDIP,
    VNHLKTCMC,
    VNHLKIMCP,
    VNHLKIDIP,
    VNHLKPMCP,
    VNHLKPDIP,
    VNHLKRTIP
)
availableJointsGroupNames(
    VNHLRKT,
    VNHLRKM,
    VNHLRKI,
    VNHLRKR,
    VNHLRKP,
    VNIPOAll
)

```

```.log
# VNIPOAll
{
    VNHLKIDIP = "[0.350816; 0.344648]";
    VNHLKIMCP = "[0.203235; 0.273218]";
    VNHLKIPIP = "[0.255140; 0.318929]";
    VNHLKITIP = "[0.430193; 0.372914]";
    VNHLKMDIP = "[0.401088; 0.339046]";
    VNHLKMMCP = "[0.214535; 0.259824]";
    VNHLKMPIP = "[0.311639; 0.300414]";
    VNHLKMTIP = "[0.467750; 0.365228]";
    VNHLKPDIP = "[0.441783; 0.296928]";
    VNHLKPMCP = "[0.196608; 0.222184]";
    VNHLKPPIP = "[0.293252; 0.243112]";
    VNHLKPTIP = "[0.500727; 0.321662]";
    VNHLKRDIP = "[0.422160; 0.319209]";
    VNHLKRMCP = "[0.205185; 0.249156]";
    VNHLKRPIP = "[0.326009; 0.285425]";
    VNHLKRTIP = "[0.477980; 0.343198]";
    VNHLKTCMC = "[0.173057; 0.244838]";
    VNHLKTIP = "[0.339841; 0.309450]";
    VNHLKTMP = "[0.231377; 0.279885]";
    VNHLKTTIP = "[0.412918; 0.348824]";
    VNHLKWRI = "[0.144244; 0.148627]";
}
```

[Body Anatomy: Upper Extremity Joints | The Hand Society](https://www.assh.org/handcare/safety/joints)

#### `VNImageRequestHandler`

> æ¦‚è¦
> ã“ã®ãƒãƒ³ãƒ‰ãƒ©ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹ã¨ã€1 ã¤ã®ç”»åƒã«å¯¾ã—ã¦ Vision ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œã§ãã‚‹ã€‚ä½œæˆæ™‚ã«ç”»åƒã¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å®Œäº†ãƒãƒ³ãƒ‰ãƒ©ã‚’æŒ‡å®šã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã« performRequests:error: ã‚’å‘¼ã³å‡ºã™ã€‚

# ğŸ“ 2022/10/21

## ãƒ‡ãƒã‚¤ã‚¹ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆé–¢ä¿‚ã‚’æ•´ç†

[detector.py](https://gist.github.com/jsbain/424d4fe1a3c0b1ae3fd705d72f665c1e)

`AVCaptureDevice.defaultDeviceWithDeviceType_mediaType_position_(_builtInWideAngleCamera, _video, _front)`

ã ã‚ã ã‹ã‚‰ã€

`videoDevice = AVCaptureDevice.devices()[1]`

Pythonista ãŒã‚‚ã†èµ·å‹•ã—ã¦ã‚‹ã‹ã‚‰ï¼Ÿï¼ˆèª­ã¿è¾¼ã‚“ã§ã‚‹ã‹ã‚‰ï¼Ÿï¼‰

`420f` = `1111970369`

ã¡ã‚ƒã‚“ã¨ç¢ºèªã™ã‚‹

> Bi-Planar Component Y'CbCr 8-bit 4:2:0, full-range (luma=[0,255] chroma=[1,255]). baseAddr points to a big-endian CVPlanarPixelBufferInfo_YCbCrBiPlanar struct.

[kCVPixelFormatType_420YpCbCr8BiPlanarFullRange | Apple Developer Documentation](https://developer.apple.com/documentation/corevideo/1563591-pixel_format_identifiers/kcvpixelformattype_420ypcbcr8biplanarfullrange?language=objc)

# ğŸ“ 2022/10/20

## é †ç•ª

- Pythonista ã® draw ä»¥å¤–ã§æã‘ã‚‹ã‹ç¢ºèª
  - `CAShapeLayer`
  - `UIBezierPath`
- ã‚­ãƒ£ãƒ—ãƒãƒ£
  - `CameraViewController`
  - `AVCaptureSession` é–¢ä¿‚
    - ãŸã ç”»é¢ä¸Šã«å‡ºã™ã“ã¨ã¯æˆåŠŸ

## `self.objc_instance.layer()`

å®Ÿè£…ã®ä»•æ–¹ã¡ãŒã†

[Swift, Objective-C ã‚’ Xamarin.iOS ã«ç§»æ¤ã™ã‚‹éš›ã®ãƒã‚¤ãƒ³ãƒˆï¼ˆ2ï¼‰ã€€ UIView.Layer ã®å·®ã—æ›¿ãˆ - å€‹äººçš„ãªãƒ¡ãƒ¢](https://hiro128.hatenablog.jp/entry/2017/09/30/234916)

ä½™è£•ãŒã‚ã£ãŸã‚‰èª¿ã¹ã‚‹

## ã‚«ãƒ¡ãƒ©ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹

è‰²ã€…ãªã“ã¨ã‚å‚è€ƒã«ã—ãªãŒã‚‰ã€delegate ã¾ã§å®Ÿè£…

## `dispatch_get_main_queue`

`main` ã¯ã€æ°—è»½ã«å‘¼ã¹ãªã„

[how can i access dispatch_get_main_queue | omz:forum](https://forum.omz-software.com/topic/6204/how-can-i-access-dispatch_get_main_queue/2)

## delegate ã‚’ Class å†…ã«é…ç½®ï¼Ÿ

buffer ã‚’å¤‰æ•°ã¨ã—ã¦æŒã¤ã«ã¯ã€Class å†…ã‹ã—ã‚‰ï¼Ÿ

ãƒ¡ã‚½ãƒƒãƒ‰åŒ–ã—ã¦ã€Class å†…ã«è¨­ç½®ã—ã¦ã€`self` ã§å‘¼ã³å‡ºã™ã‚ˆã†ã«ã—ãŸ

## `autorelease()` ã„ã‚‹ã„ã‚‰ãªã„å•é¡Œ

ä½•ã‚’åŸºæº–ã«å¿…è¦ãªã‚“ã ã‚ã†ã‹ï¼Ÿ

delegate ã®ã¨ã“ã‚ã¯ã€`autorelease()` ã‚’ä»˜ã‘ã¦ãŠã

## `recognizedPoints(.thumb)` ã®`.thumb` ã¨ã‹ã‚’æ¢ã™

ã“ã‚Œã‹ï¼Ÿ`VNHumanHandPoseObservationJointsGroupNameThumb`

[VNHumanHandPoseObservationJointsGroupNameThumb | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointsgroupnamethumb?language=objc)

[VNHumanHandPoseObservationJointsGroupName | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointsgroupname?changes=_10_8&language=objc)

[.NET API Catalog](https://apisof.net/catalog/07929f76-9c5c-2bd2-50d0-6a477473f016)

ã†ã¬ãƒ¼`None` ã‚’å–å¾—ã™ã‚‹ã…ãƒ¼

# ğŸ“ 2022/10/17

[Detect Body and Hand Pose with Vision - WWDC20 - Videos - Apple Developer](https://developer.apple.com/videos/play/wwdc2020/10653/)

[Detecting Hand Poses with Vision | Apple Developer Documentation](https://developer.apple.com/documentation/vision/detecting_hand_poses_with_vision?language=objc)
